<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>louguanstar.com</title>
    <description>Write an awesome description for your new site here. You can edit this line in _config.yml. It will appear in your document head meta (for Google search results) and in your feed.xml site description.
</description>
    <link>http://louguanstar.com/</link>
    <atom:link href="http://louguanstar.com/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Sun, 16 Jul 2017 16:52:17 +0800</pubDate>
    <lastBuildDate>Sun, 16 Jul 2017 16:52:17 +0800</lastBuildDate>
    <generator>Jekyll v3.1.3</generator>
    
      <item>
        <title>总结之前工作中常用的命令</title>
        <description>&lt;h3 id=&quot;hadoop&quot;&gt;关于hadoop&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;#手动切换active与standby
sudo -u hdfs hdfs haadmin -failover nn2 nn1
#查看namenode状态
sudo -u hdfs hdfs haadmin -getServiceState nn1
#启动standby
sudo -u hdfs hadoop namenode -bootstrapStandby
#退出safe mode
sudo -u hdfs hadoop dfsadmin -safemode leave
#刷新hdfs节点
sudo hadoop dfsadmin -refreshNodes
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;yarn&quot;&gt;关于YARN&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;#查看application日志
yarn logs -applicationId application_..._0010
#杀掉某个job
sudo -u yarn yarn application -kill application_..._0004
#刷新yarn节点
sudo yarn rmadmin -refreshNodes
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;kerberos&quot;&gt;Kerberos&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;#Kerberos初始化简要
krb5.conf
kadm5.acl
kdb5_util create -r LOUGUANSTAR.COM -s
shell% kadmin.local
kadmin.local: addprinc admin/admin@LOUGUANSTAR.COM
krb5kdc
kadmind
#列出所有principal
kadmin.local -q &quot;list_principals&quot;
kadmin.local -q &quot;listprincs&quot;
#添加principal
kadmin.local -q &quot;addprinc -randkey test/test1.louguanstar.com@LOUGUANSTAR.COM&quot;
#生成keytab
kadmin.local -q &quot;ktadd -k impala116.keytab test/test1.louguanstar.com@LOUGUANSTAR.COM&quot;
kadmin.local -q &quot;ktadd -k impala163.keytab test/test1.louguanstar.com@LOUGUANSTAR.COM adc/test1.louguanstar.com@LOUGUANSTAR.COM&quot;
#认证
kinit -kt yarn.keytab yarn/yarn.louguanstar.com@LOUGUANSTAR.COM
#删除principal
kadmin.local -q &quot;delprinc spark_deploy@LENOVOMM2.COM&quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;hive&quot;&gt;Hive&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;#hdfs集群名更换后hive不能启动，需要修改metastore
UPDATE `SDS` SET `LOCATION` = replace(LOCATION, &#39;master:9000&#39;, &#39;louguanstar&#39;);
#hive查看建表语句
show create table dbname.tablename
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;section&quot;&gt;其他&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;#查看某个java进程的“日志”
jstack PID
#jvm申请内存问题，修改Linux内存管理方式
sysctl vm.overcommit_memory=1
/etc/sysctl.conf
vm.overcommit_memory = 1
#CDH使用的所有端口
cdh port:https://www.cloudera.com/documentation/enterprise/5-2-x/topics/cdh_ig_ports_cdh5.html#topic_9_1
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
        <pubDate>Sat, 15 Jul 2017 00:00:00 +0800</pubDate>
        <link>http://louguanstar.com/2017/07/15/%E6%80%BB%E7%BB%93%E4%B9%8B%E5%89%8D%E5%B7%A5%E4%BD%9C%E4%B8%AD%E5%B8%B8%E7%94%A8%E7%9A%84%E5%91%BD%E4%BB%A4.html</link>
        <guid isPermaLink="true">http://louguanstar.com/2017/07/15/%E6%80%BB%E7%BB%93%E4%B9%8B%E5%89%8D%E5%B7%A5%E4%BD%9C%E4%B8%AD%E5%B8%B8%E7%94%A8%E7%9A%84%E5%91%BD%E4%BB%A4.html</guid>
        
        
      </item>
    
      <item>
        <title>关于mysql</title>
        <description>&lt;h3 id=&quot;mysql&quot;&gt;关于mysql设置&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;查看mysql状态&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;show status
#一些说明
   Threads_connected  当前连接数
   Connections  试图连接到(无论是否成功)MySQL服务器连接数。
   Max_used_connections  服务器启动后已经同时使用的连接的最大数量。
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;查看最大连接数&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;show variables like &#39;%max_connections%&#39;;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;设置最大连接数&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;set GLOBAL max_connections=连接数;
flush privileges
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;修改配置文件设置最大连接数&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;修改或者添加/etc/my.cnf中的max_connections参数
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;显示所有用户当前执行的连接&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;show global variables like &#39;%timeout%&#39;;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;设置server超时时间（秒）&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;msyql&amp;gt; set global wait_timeout=300;
msyql&amp;gt; set global interactive_timeout=300;
show full processlist   显示当前正在执行的mysql连接
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;设置表为只读&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;找到表数据
myisampack -f VERSION.MYI
myisamchk -rq VERSION
mysqladmin -uroot flush-tables -p
#解除
myisamchk --unpack VERSION.MYI
mysqladmin -uroot flush-tables -p
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;其他&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;mysqld --skip-grant-tables &amp;amp;   #mysql忘记密码处理，同时可以处理密码旧格式问题
#重置密码
update user set password=password(&quot;new_pass&quot;) where user=&quot;root&quot;;
UPDATE mysql.user SET password=PASSWORD(&#39;123456&#39;) WHERE user=&#39;root&#39;;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
        <pubDate>Fri, 07 Jul 2017 00:00:00 +0800</pubDate>
        <link>http://louguanstar.com/2017/07/07/%E5%85%B3%E4%BA%8Emysql.html</link>
        <guid isPermaLink="true">http://louguanstar.com/2017/07/07/%E5%85%B3%E4%BA%8Emysql.html</guid>
        
        
      </item>
    
      <item>
        <title>Cdh安装</title>
        <description>&lt;h3 id=&quot;section&quot;&gt;准备工作&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;java相应版本&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;mysql(mariadb/postgresql)&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;#以mariadb为例
https://mariadb.com/kb/en/mariadb/installing-mariadb-binary-tarballs/
groupadd mysql
useradd -g mysql mysql
tar -zxvf mariadb-10.1.13-linux-x86_64.tar.gz
ln -s mariadb-10.1.13-linux-x86_64 mysql
cd mysql
./scripts/mysql_install_db --user=mysql
chown -R root .
chown -R mysql data
./bin/mysqld_safe --user=mysql &amp;amp;
./bin/mysqladmin -u root password &#39;123456&#39;
cp support-files/mysql.server /etc/init.d/mysql.server

grant all privileges on *.* to root@&#39;%&#39; IDENTIFIED BY &#39;123456&#39; WITH GRANT OPTION;
flush privileges;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;parcel&quot;&gt;使用parcel&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;mkdir /opt/cloudera-manager
tar -xzvf cloudera-manager-el5-cm5.6.0_x86_64.tar.gz -C /opt/cloudera-manager
useradd --system --home=/opt/cloudera-manager/cm-5.6.0/run/cloudera-scm-server --no-create-home --shell=/bin/false --comment &quot;Cloudera SCM User&quot; cloudera-scm
#prepare database
./scm_prepare_database.sh mysql localhost cdh -uroot -p123456

mkdir /var/log/cloudera-scm-server
chown cloudera-scm:cloudera-scm /var/log/cloudera-scm-server

mkdir -p /opt/cloudera/parcel-repo
mkdir -p /opt/cloudera/parcels
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;rpm&quot;&gt;使用rpm包&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;#server:
rpm -ivh cloudera-manager-daemons-5.6.0-1.cm560.p0.54.el5.x86_64.rpm
rpm -ivh cloudera-manager-server-5.6.0-1.cm560.p0.54.el5.x86_64.rpm

#agent:
rpm -ivh cloudera-manager-daemons-5.6.0-1.cm560.p0.54.el5.x86_64.rpm
rpm -ivh cloudera-manager-agent-5.6.0-1.cm560.p0.54.el5.x86_64.rpm
#databae
/usr/share/cmf/schema/scm_prepare_database.sh mysql -h localhost -uroot -p123456 scm scm scm
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;yum&quot;&gt;使用本地yum源安装&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;hdfs&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;#Namenode server:
yum -y install hadoop hadoop-hdfs hadoop-client hadoop-doc hadoop-debuginfo hadoop-hdfs-namenode hadoop-httpfs

#Secondnary namenode server:
yum -y install hadoop-hdfs-secondarynamenode

#Data node:
yum -y install hadoop hadoop-hdfs hadoop-client hadoop-doc hadoop-debuginfo hadoop-hdfs-datanode

#journal node:
yum -y install hadoop-hdfs-journalnode hadoop-hdfs-zkfc
#creat dirs
mkdir -p /data/hadoop/dfs/{data,jn,name}
chown -R hdfs:hdfs /data/hadoop/dfs/

mkdir -p /data/hadoop/tmp/dfs/{data,jn,name}
chown -R hdfs:hdfs /data/hadoop/tmp
#format hdfs
sudo -u hdfs hadoop namenode -format
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;ul&gt;
  &lt;li&gt;yarn&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;#resource manager:
yum -y install hadoop-yarn hadoop-yarn-resourcemanager hadoop-mapreduce-historyserver hadoop-yarn-proxyserver

#node manager:
yum -y install hadoop-yarn hadoop-yarn-nodemanager hadoop-mapreduce
#create dirs
mkdir -p /data/hadoop/yarn/{local,logs}
chown -R yarn:yarn /data/hadoop/yarn
sudo -u hdfs hadoop fs -mkdir -p /var/log/hadoop-yarn/apps
sudo -u hdfs hadoop fs -chown -R yarn:yarn /var/log/hadoop-yarn
mkdir -p /data/hadoop/tmp/mapred/staging/history/done
chown -R yarn:yarn /data/hadoop/tmp/mapred
sudo -u hdfs hadoop fs -mkdir -p /data/hadoop/tmp/mapred
sudo -u hdfs hadoop fs -chown -R mapred:mapred /data/hadoop/tmp/mapred
#start process
/etc/init.d/hadoop-yarn-resourcemanager start
/etc/init.d/hadoop-yarn-nodemanager start
/etc/init.d/hadoop-mapreduce-historyserver start
#run a test
sudo -u hdfs hadoop jar /usr/lib/hadoop-mapreduce/hadoop-mapreduce-examples.jar pi 10 10
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;hive&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;#metastore:
yum -y install hive hive-metastore hive-server2 hive-jdbc
yum -y install hive hive-server2 hive-jdbc
#mysql for metastore
yum -y install mysql-libs mysql-devel
ln -s /usr/share/java/mysql-connector-java.jar /usr/lib/hive/lib/mysql-connector-java.jar
mysql -u root -p123456 -e &quot;
    CREATE DATABASE metastore;
    USE metastore;
    SOURCE /usr/lib/hive/scripts/metastore/upgrade/mysql/hive-schema-1.1.0.mysql.sql;
    CREATE USER &#39;hiveuser&#39;@&#39;master&#39; IDENTIFIED BY &#39;123456&#39;;
    GRANT ALL PRIVILEGES ON metastore.* TO &#39;hiveuser&#39;@&#39;master&#39;;
    GRANT ALL PRIVILEGES ON metastore.* TO &#39;hiveuser&#39;@&#39;%&#39;;
    FLUSH PRIVILEGES;
&quot;
#create dirs
sudo -u hdfs hadoop fs -mkdir -p /user/hive/warehouse
sudo -u hdfs hadoop fs -chown -R hive:hive /user/hive
sudo -u hdfs hadoop fs -chmod 1777 /user/hive/warehouse
#start process
/etc/init.d/hive-metastore start
/etc/init.d/hive-server2 start

hive开启并发必须启动zookeeper
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
        <pubDate>Wed, 05 Jul 2017 00:00:00 +0800</pubDate>
        <link>http://louguanstar.com/2017/07/05/CDH%E5%AE%89%E8%A3%85.html</link>
        <guid isPermaLink="true">http://louguanstar.com/2017/07/05/CDH%E5%AE%89%E8%A3%85.html</guid>
        
        
      </item>
    
      <item>
        <title>Hdsf上get数据后文件大10倍</title>
        <description>&lt;h4 id=&quot;hdfsgetgethdfs10&quot;&gt;从HDFS上get下一个目录，get下之后目录体积为HDFS上10+倍&lt;/h4&gt;

&lt;h3 id=&quot;section&quot;&gt;问题产生&lt;/h3&gt;

&lt;p&gt;从HDFS上get下一个目录，目录原本很小以为会很快，查看了下本地目录大小，却逐渐超过hdfs上10倍之多&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;HDFS上文件大小
[louguanstar@localhost ~]$ sudo hadoop fs -du -s -h /user/hive/warehouse/test.db
53.3 M  160.0 M  /user/hive/warehouse/test.db

完成后本地文件大小
[louguanstar@localhost ~]$ du -sh test.db
642M    test.db

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;推测可能是文件系统block大小影响的，但是10倍之多有些不可思议，好奇心驱使所以验证下
```
查看文件系统block大小
[louguanstar@localhost ~]$ sudo /sbin/tune2fs -l /dev/sda2
tune2fs 1.39 (29-May-2006)
Filesystem volume name:   /
…
Filesystem OS type:       Linux
Inode count:              25624576
Block count:              25599577
Reserved block count:     1279978
Free blocks:              14624498
Free inodes:              25103644
First block:              0
Block size:               4096
…&lt;/p&gt;

&lt;p&gt;统计文件个数
[louguanstar@localhost ~]$ ls -lR test.db |grep “^-“|wc -l
149179&lt;/p&gt;

&lt;p&gt;```&lt;/p&gt;

&lt;h3 id=&quot;section-1&quot;&gt;总结&lt;/h3&gt;
&lt;p&gt;文件数居然有如此之多，大致计算下&lt;code class=&quot;highlighter-rouge&quot;&gt;149179*4/1024=582.73046875&lt;/code&gt;及时每个文件都小于4K在本地文件系统已有583MB，此时结果已经很明了了&lt;/p&gt;
</description>
        <pubDate>Fri, 17 Mar 2017 00:00:00 +0800</pubDate>
        <link>http://louguanstar.com/2017/03/17/HDSF%E4%B8%8Aget%E6%95%B0%E6%8D%AE%E5%90%8E%E6%96%87%E4%BB%B6%E5%A4%A710%E5%80%8D.html</link>
        <guid isPermaLink="true">http://louguanstar.com/2017/03/17/HDSF%E4%B8%8Aget%E6%95%B0%E6%8D%AE%E5%90%8E%E6%96%87%E4%BB%B6%E5%A4%A710%E5%80%8D.html</guid>
        
        
      </item>
    
      <item>
        <title>一次根目录满找不到占用空间文件问题</title>
        <description>&lt;h4 id=&quot;server98&quot;&gt;某台server突然根目录占用空间98%，但找不到占用空间的文件&lt;/h4&gt;

&lt;h3 id=&quot;section&quot;&gt;问题产生&lt;/h3&gt;

&lt;p&gt;发现一台server根目录占用满，使用df -h命令查看，根目录确实占用已90%&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[root@localhost /]# df -h
Filesystem            Size  Used Avail Use% Mounted on
/dev/sda1             190G  172G  8.0G  96% /
/dev/sdb1             2.7T  1.4T  1.2T  56% /hahaha

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;使用du命令查找/目录下大文件；使用&lt;code class=&quot;highlighter-rouge&quot;&gt;lsof | grep delete&lt;/code&gt;没有发现已删除文件进程仍占用的
```
[root@localhost ~]# du -sh –exclude=hahaha /*
8.5M    /bin
6.5M    /boot
4.0K    /CmdTool.log
388K    /dev
126M    /etc
116M    /home
149M    /lib
35M     /lib64
16K     /lost+found
8.0K    /media
12K     /MegaSAS.log
8.0K    /misc
7.9G    /mnt
17M     /Nagios-Plugin
44M     /opt
0       /proc
356K    /root
40M     /sbin
8.0K    /selinux
8.0K    /srv
0       /sys
100K    /tftpboot
2.2M    /tmp
6.2G    /usr
1.2G    /var&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
### 解决问题
将/目录再次挂载到/mnt下查看，发现异常,然后进入/mnt/hahaha目录下删除文件
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;[root@localhost /]# mount -o bind / /mnt
[root@localhost /]# du -sh   /mnt/*
8.5M    /mnt/bin
8.0K    /mnt/boot
4.0K    /mnt/CmdTool.log
165G    /mnt/hahaha
…
6.2G    /mnt/usr
1.2G    /mnt/var&lt;/p&gt;

&lt;p&gt;```&lt;/p&gt;

&lt;h3 id=&quot;section-1&quot;&gt;总结&lt;/h3&gt;
&lt;p&gt;在删除&lt;code class=&quot;highlighter-rouge&quot;&gt;/mnt/hahaha&lt;/code&gt;目录下的异常文件时先检查下文件内容以及使用&lt;code class=&quot;highlighter-rouge&quot;&gt;lsof&lt;/code&gt;确认下文件是否在被使用&lt;/p&gt;

&lt;p&gt;最终问题产生的根源是由于挂载的不细心，由于服务器一些基本维护另有分工所以造成了发现问题有些难度（和问题的产生）&lt;/p&gt;
</description>
        <pubDate>Mon, 06 Mar 2017 00:00:00 +0800</pubDate>
        <link>http://louguanstar.com/2017/03/06/%E4%B8%80%E6%AC%A1%E6%A0%B9%E7%9B%AE%E5%BD%95%E6%BB%A1%E6%89%BE%E4%B8%8D%E5%88%B0%E5%8D%A0%E7%94%A8%E7%A9%BA%E9%97%B4%E6%96%87%E4%BB%B6%E9%97%AE%E9%A2%98.html</link>
        <guid isPermaLink="true">http://louguanstar.com/2017/03/06/%E4%B8%80%E6%AC%A1%E6%A0%B9%E7%9B%AE%E5%BD%95%E6%BB%A1%E6%89%BE%E4%B8%8D%E5%88%B0%E5%8D%A0%E7%94%A8%E7%A9%BA%E9%97%B4%E6%96%87%E4%BB%B6%E9%97%AE%E9%A2%98.html</guid>
        
        
      </item>
    
      <item>
        <title>Centos安装vsftp</title>
        <description>&lt;h3 id=&quot;section&quot;&gt;本地用户/系统用户&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;useradd -g ftp -d /vsftp/test1 -s /sbin/nologin -M test1
useradd -g ftp -d /vsftp/test2 -s /sbin/nologin -M test2
useradd -g ftp -d /vsftp/test3 -s /sbin/nologin -M test3

mkdir -p /vsftp/test1 /vsftp/test2 /vsftp/test3;chown -R ftp:ftp /vsftp
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;ul&gt;
  &lt;li&gt;配置文件样例&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;#user test1 config file sample in /etc/vsftp/vconf

local_root=/vsftp/test1
anon_world_readable_only=NO
anon_upload_enable=YES
anon_mkdir_write_enable=YES
anon_other_write_enable=YES

vsftp.conf  sample
anonymous_enable=NO
local_enable=YES
chroot_local_user=YES
user_config_dir=/ect/vsftpd/vconf
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;上传文件的权限&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;用户以及组与ftp用户相同&lt;/p&gt;

&lt;h3 id=&quot;section-1&quot;&gt;虚拟用户&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;yum install db4-utils
db_load -T -t hash -f /etc/vsftpd/user.txt /etc/vsftpd/vftpuser.db
change /etc/pam.d/vsftp like this:
auth required /lib64/security/pam_userdb.so db=/etc/vsftpd/vftpuser
account required /lib64/security/pam_userdb.so db=/etc/vsftpd/vftpuser
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;vsftp.conf sample&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;anonymous_enable=NO
anon_upload_enable=YES
anon_mkdir_write_enable=YES
anon_other_write_enable=YES
guest_enable=YES
guest_username=ftp
user_sub_token=$USER
local_root=/vsftp/$USER
hide_ids=YES
virtual_use_local_privs=YES
local_enable=YES
chroot_local_user=YES
write_enable=YES
local_umask=022
pam_service_name=vsftpd  #pam file path /etc/pam.d/vsftpd
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;user config file sample not correct in centos5&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;#user test1 config file sample in /etc/vsftp/vconf

local_root=/vsftp/vs1
write_enable=YES
download_enable=YES
anon_world_readable_only=NO
anon_upload_enable=YES
anon_mkdir_write_enable=YES
anon_other_write_enable=YES
local_umask=022
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;uploaded file mode&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;file user,group are the guset user’s&lt;/p&gt;
</description>
        <pubDate>Wed, 18 Jan 2017 00:00:00 +0800</pubDate>
        <link>http://louguanstar.com/2017/01/18/CentOS%E5%AE%89%E8%A3%85vsftp.html</link>
        <guid isPermaLink="true">http://louguanstar.com/2017/01/18/CentOS%E5%AE%89%E8%A3%85vsftp.html</guid>
        
        
      </item>
    
      <item>
        <title>关于yum的变量</title>
        <description>&lt;p&gt;使用yum安装软件的Linux发行版，其关于yum源的配置一般如下&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[base]
name=CentOS-$releasever - Base - 163.com
baseurl=http://mirrors.163.com/centos/$releasever/os/$basearch/
#mirrorlist=http://mirrorlist.centos.org/?release=$releasever&amp;amp;arch=$basearch&amp;amp;repo=os
gpgcheck=1
gpgkey=http://mirror.centos.org/centos/RPM-GPG-KEY-CentOS-6

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;其中出现了&lt;code class=&quot;highlighter-rouge&quot;&gt;$releasever&lt;/code&gt; , &lt;code class=&quot;highlighter-rouge&quot;&gt;$basearch&lt;/code&gt;这两个变量，于是搜索资料学习了下&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;查看变量&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;可用如下命令查看yum中的变量&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; python -c &#39;import yum, pprint; yb = yum.YumBase(); pprint.pprint(yb.conf.yumvar, width=1)&#39;

 输出如下：
 Loaded plugins: fastestmirror
 {&#39;arch&#39;: &#39;ia32e&#39;,
  &#39;basearch&#39;: &#39;x86_64&#39;,
  &#39;releasever&#39;: &#39;6&#39;,
  &#39;uuid&#39;: &#39;d9361a3a-ca57-4c50-989d-7c5e09dba049&#39;}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;Ubuntu中的apt源配置文件样例&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;相比与yum，apt的源配置文件大致如下&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ubuntu:
deb http://mirrors.ustc.edu.cn/ubuntu/ xenial main restricted universe multiverse
deb http://mirrors.ustc.edu.cn/ubuntu/ xenial-security main restricted universe multiverse
deb http://mirrors.ustc.edu.cn/ubuntu/ xenial-updates main restricted universe multiverse
deb http://mirrors.ustc.edu.cn/ubuntu/ xenial-proposed main restricted universe multiverse
deb http://mirrors.ustc.edu.cn/ubuntu/ xenial-backports main restricted universe multiverse
deb-src http://mirrors.ustc.edu.cn/ubuntu/ xenial main restricted universe multiverse
deb-src http://mirrors.ustc.edu.cn/ubuntu/ xenial-security main restricted universe multiverse
deb-src http://mirrors.ustc.edu.cn/ubuntu/ xenial-updates main restricted universe multiverse
deb-src http://mirrors.ustc.edu.cn/ubuntu/ xenial-proposed main restricted universe multiverse
deb-src http://mirrors.ustc.edu.cn/ubuntu/ xenial-backports main restricted universe multiverse
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;yum中两个相同软件名只有版本不同&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;今天同样遇到一个问题，用yum查看安装的软件时发现有两个完全一样的软件，可用如下方式处理&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;yum list installed | grep datanode
hadoop-hdfs-datanode.x86_64    cdh5.5.0************
hadoop-hdfs-datanode.x86_64    cdh5.2.0************

处理方式：

sudo rpm -ev --noscripts --allmatches hadoop-hdfs-datanode
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
        <pubDate>Tue, 19 Jul 2016 00:00:00 +0800</pubDate>
        <link>http://louguanstar.com/2016/07/19/%E5%85%B3%E4%BA%8Eyum%E7%9A%84%E5%8F%98%E9%87%8F.html</link>
        <guid isPermaLink="true">http://louguanstar.com/2016/07/19/%E5%85%B3%E4%BA%8Eyum%E7%9A%84%E5%8F%98%E9%87%8F.html</guid>
        
        
      </item>
    
      <item>
        <title>Awk使用nr与fnr合并两个文件</title>
        <description>&lt;h3 id=&quot;awknrfnr&quot;&gt;使用awk的NR与FNR合并两个文件&lt;/h3&gt;
&lt;p&gt;工作遇到一个需求有如下两个文件：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;file a&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;store.louguanstar.com	5.6.7.8
app.louguanstar.com	1.2.3.4
foo.louguanstar.com	a.b.c.d
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;file b&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;foo.louguanstar.com	1300
store.louguanstar.com	1100
app.louguanstar.com	1200
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;现在需要把这个文件处理为如下样式然后加上xml文件头就行，用作hadoop集群的topology文件&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;lt;node name=&quot;foo.louguanstar.com&quot; rack=&quot;/avatar/1300&quot;/&amp;gt;
&amp;lt;node name=&quot;a.b.c.d&quot; rack=&quot;/avatar/1300&quot;/&amp;gt;
&amp;lt;node name=&quot;store.louguanstar.com&quot; rack=&quot;/avatar/1100&quot;/&amp;gt;
&amp;lt;node name=&quot;5.6.7.8&quot; rack=&quot;/avatar/1100&quot;/&amp;gt;
&amp;lt;node name=&quot;app.louguanstar.com&quot; rack=&quot;/avatar/1200&quot;/&amp;gt;
&amp;lt;node name=&quot;1.2.3.4&quot; rack=&quot;/avatar/1200&quot;/&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;awk可以使用自身变量NR和FNR来处理多个文件。&lt;/p&gt;

&lt;p&gt;NR：awk开始执行程序后所读取的数据行数。&lt;/p&gt;

&lt;p&gt;FNR：awk当前读取的记录数，FNR值小于等于NR（当awk读取第二个文件时，FNR是从0开始重新计数，而NR继续累加）。&lt;/p&gt;

&lt;p&gt;NR==FNR：用于在读取两个或两个以上的文件时，判断是不是在读取第一个文件。&lt;/p&gt;

&lt;p&gt;awk处理多个文件的基本语法是:
awk -F分隔符 ‘BEGIN { 初始化 } { 循环执行部分 } END { 结束处理 }’ file1 file2&lt;/p&gt;

&lt;p&gt;其中BEGIN和END可以省略，-F用来指定分割符&lt;/p&gt;

&lt;p&gt;最后使用如下命令就可以得到上面的结果：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;awk &#39;NR==FNR{a[$1]=$2}FNR&amp;lt;NR{print $1,a[$1],$2}&#39; a b | awk &#39;{print &quot;&amp;lt;node name=\&quot;&quot;$1&quot;\&quot; rack=\&quot;/avatar/&quot;$3&quot;\&quot;/&amp;gt;\n&amp;lt;node name=\&quot;&quot;$2&quot;\&quot; rack=\&quot;/avatar/&quot;$3&quot;\&quot;/&amp;gt;&quot;}&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;后面又发现使用awk可以统计每块网卡的网速，命令如下：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;tmp1=`mktemp`
tmp2=`mktemp`
/bin/cat /proc/net/dev | awk &#39;NR&amp;gt;2 {print $1&quot; tx &quot;$2&quot; ,rx &quot;$10}&#39; |sed &#39;s/://&#39; &amp;gt;$tmp1
sleep 5
/bin/cat /proc/net/dev | awk &#39;NR&amp;gt;2 {print $1&quot; tx &quot;$2&quot; ,rx &quot;$10}&#39; |sed &#39;s/://&#39; &amp;gt;$tmp2

echo &quot;,
    \&quot;band_width_out\&quot;:{&quot;
awk &#39;NR==FNR{a[$1]=$3}NR&amp;gt;FNR{print &quot;        \&quot;&quot;$1&quot;\&quot;:\&quot;&quot;($3-a[$1])/5/1024&quot;MB/s\&quot;,&quot;}&#39; $tmp1 $tmp2

echo &quot;    },
    \&quot;band_width_in\&quot;:{&quot;
awk &#39;NR==FNR{a[$1]=$NF}NR&amp;gt;FNR{print &quot;        \&quot;&quot;$1&quot;\&quot;:\&quot;&quot; ($NF-a[$1])/5/1024&quot;MB/s\&quot;,&quot;}&#39; $tmp1 $tmp2
echo &quot;    }&quot;
rm $tmp1 $tmp2
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;section&quot;&gt;参考文档&lt;/h3&gt;

&lt;blockquote&gt;
  &lt;ol&gt;
    &lt;li&gt;&lt;a href=&quot;http://blog.csdn.net/imzoer/article/details/8734474&quot;&gt;http://blog.csdn.net/imzoer/article/details/8734474&lt;/a&gt;&lt;/li&gt;
  &lt;/ol&gt;
&lt;/blockquote&gt;
</description>
        <pubDate>Tue, 21 Jun 2016 00:00:00 +0800</pubDate>
        <link>http://louguanstar.com/2016/06/21/awk%E4%BD%BF%E7%94%A8NR%E4%B8%8EFNR%E5%90%88%E5%B9%B6%E4%B8%A4%E4%B8%AA%E6%96%87%E4%BB%B6.html</link>
        <guid isPermaLink="true">http://louguanstar.com/2016/06/21/awk%E4%BD%BF%E7%94%A8NR%E4%B8%8EFNR%E5%90%88%E5%B9%B6%E4%B8%A4%E4%B8%AA%E6%96%87%E4%BB%B6.html</guid>
        
        
      </item>
    
      <item>
        <title>Yarn配置kerberos需要在所有nodemanager添加用户</title>
        <description>&lt;p&gt;yarn添加kerberos认证需要在所有nodemanager上添加kerberos principal用户&lt;/p&gt;

&lt;h3 id=&quot;section&quot;&gt;发现问题&lt;/h3&gt;

&lt;p&gt;同事反应yarn提交任务有问题，发现yarn配置了kerberos认证，于是给新建的用户添加了principal，并且生成了keytab&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;添加principal
kadmin.local -q &quot;addprinc -randkey spark_deploy@LOUGUANSTAR.COM&quot;
生成keytab
kadmin.local -q &quot;ktadd -k spark_deploy.keytab spark_deploy@LOUGUANSTAR.COM&quot;

其他kerberos操作：
删除principal
kadmin.local -q &quot;delprinc spark_deploy@LOUGUANSTAR.COM&quot;
查看所有principal
./kadmin.local -q &quot;listprincs&quot; | grep spark
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;然后进行kerberos认证，尝试提交任务&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kinit -kt spark_deploy.keytab spark_deploy
hadoop jar  /usr/lib/hadoop-mapreduce/hadoop-mapreduce-examples-2.6.0-cdh5.5.2.jar pi 10 100
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;任务很快结束，jobhistory中找不到日志，resourcemanager中的报错信息很简短，错误信息大致如下：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;main : run as user is spark_deploy
main : requested yarn user is spark_deploy
User spark_deploy not found
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;section-1&quot;&gt;解决问题&lt;/h3&gt;

&lt;p&gt;始终觉得问题在设置yarn.nodemanager.linux-container-executor的问题上，如果没有设置kerberos认证那么可以指定运行yarn.nodemanager.linux-container-executor；配置了kerberos之后yarn任务的用户为kerberos principal中的用户如：spark_deploy@LOUGUANSTAR.COM中即为spark_deploy
经历了多半天各种调试，最后发现：&lt;code class=&quot;highlighter-rouge&quot;&gt;配置kerberos之后必须在每个nodemanager上新建kerberos principal中的用户&lt;/code&gt;，这样才能确保每个任务都可以在nodemanager上运行&lt;/p&gt;

&lt;p&gt;在所有nodemanager上添加spark_deploy用户，问题成功解决&lt;/p&gt;

&lt;h3 id=&quot;section-2&quot;&gt;参考文档&lt;/h3&gt;

&lt;blockquote&gt;
  &lt;ol&gt;
    &lt;li&gt;&lt;a href=&quot;https://community.cloudera.com/t5/Batch-Processing-and-Workflow/YARN-force-nobody-user-on-all-jobs-and-so-they-fail/td-p/26050&quot;&gt;https://community.cloudera.com/t5/Batch-Processing-and-Workflow/YARN-force-nobody-user-on-all-jobs-and-so-they-fail/td-p/26050&lt;/a&gt;&lt;/li&gt;
  &lt;/ol&gt;
&lt;/blockquote&gt;
</description>
        <pubDate>Mon, 06 Jun 2016 00:00:00 +0800</pubDate>
        <link>http://louguanstar.com/2016/06/06/yarn%E9%85%8D%E7%BD%AEkerberos%E9%9C%80%E8%A6%81%E5%9C%A8%E6%89%80%E6%9C%89nodemanager%E6%B7%BB%E5%8A%A0%E7%94%A8%E6%88%B7.html</link>
        <guid isPermaLink="true">http://louguanstar.com/2016/06/06/yarn%E9%85%8D%E7%BD%AEkerberos%E9%9C%80%E8%A6%81%E5%9C%A8%E6%89%80%E6%9C%89nodemanager%E6%B7%BB%E5%8A%A0%E7%94%A8%E6%88%B7.html</guid>
        
        
      </item>
    
      <item>
        <title>Linux网络基础命令</title>
        <description>&lt;p&gt;最近进行了网络迁移的工作，大致对linux的网络命令做一个简单的纪录&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;查看IP，基本网络配置&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ip addr show  显示所有网络设备的ip等基本信息
ifconfig device_name  显示某块网卡的详细信息或者所有网卡的信息
 其中的frame表示由于CRC引起的错误包的数量，过多一般是硬件问题
overruns为网卡没有来的急处理丢掉的报
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;ethtool&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ethtool -i device_name 显示网络设备驱动信息
ethtool -S device_name 显示网络设备的详细统计信息（接收到的包，发出去的报，错误包等）
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;ping命令快速测试网络质量&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ping -c count -f IP   f参数为flood ping只有root用户可执行，可以用来测试网络质量，很快的发送上万个包
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;网络测试工具，检测
iperf测试网卡速度，iftop/iptraf Linux下监测网络流量工具&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;route&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;route add -net 192.168.1.0/255.255.255.0 gw 192.168.1.1  添加一条路由记录
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;小技巧，查看每个IP连接数
&lt;code class=&quot;highlighter-rouge&quot;&gt;
sed -n &#39;s%.* src=\([0-9]*.[0-9]*.[0-9.]*\).*%\1%p&#39; /proc/net/nf_conntrack  | sort | uniq -c   #部分机器可能不发查看
&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;netstat -n | awk &#39;/^tcp/ {n=split($(NF-1),array,&quot;:&quot;);if(n&amp;lt;=2)++S[array[(1)]];else++S[array[(4)]];++s[$NF];++N} END {for(a in S){printf(&quot;%-20s %s\n&quot;, a, S[a]);++I}printf(&quot;%-20s %s\n&quot;,&quot;TOTAL_IP&quot;,I);for(a in s) printf(&quot;%-20s %s\n&quot;,a, s[a]);printf(&quot;%-20s %s\n&quot;,&quot;TOTAL_LINK&quot;,N);}&#39;    #仅TCP连接
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
        <pubDate>Tue, 31 May 2016 00:00:00 +0800</pubDate>
        <link>http://louguanstar.com/2016/05/31/Linux%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A4.html</link>
        <guid isPermaLink="true">http://louguanstar.com/2016/05/31/Linux%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A4.html</guid>
        
        
      </item>
    
  </channel>
</rss>
